import html
import re
from datetime import date, timedelta
from textwrap import dedent

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st

st.set_page_config(
    page_title="CRMíŒ€ ê¸°íšì „ ì„±ê³¼ ë¶„ì„",
    layout="wide",
    page_icon="Symbol.png",
)

REQUIRED_COLUMNS = [
    "ë³‘ì› ID",
    "ë³‘ì› ì´ë¦„",
    "ëŒ€í–‰ì‚¬ ID",
    "ëŒ€í–‰ì‚¬ ì´ë¦„",
    "ì´ë²¤íŠ¸ ID (ì‹ë³„ì)",
    "ì´ë²¤íŠ¸ ì´ë¦„",
    "ì´ë²¤íŠ¸ ê°€ê²© (text)",
    "ì¹´í…Œê³ ë¦¬ (ìµœìƒìœ„)",
    "ì¹´í…Œê³ ë¦¬ (ëŒ€)",
    "ì¹´í…Œê³ ë¦¬ (ì¤‘)",
    "ì¹´í…Œê³ ë¦¬ (ì†Œ)",
    "ëŒ€ìƒì¼",
    "ì¡°íšŒ ìˆ˜",
    "ìƒë‹´ì‹ ì²­ ìˆ˜",
]

COLUMN_ALIASES = {
    "ì´ë²¤íŠ¸ ID (ì‹ë³„ì)": ["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", "ì´ë²¤íŠ¸ ID"],
}


def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    rename_map = {}
    missing = []
    for required in REQUIRED_COLUMNS:
        candidates = COLUMN_ALIASES.get(required, [required])
        matched = next((c for c in candidates if c in df.columns), None)
        if matched:
            rename_map[matched] = required
        else:
            missing.append(required)
    if missing:
        raise ValueError(f"ë‹¤ìŒ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing)}")
    return df.rename(columns=rename_map)


@st.cache_data(show_spinner=True)
def load_data(file) -> pd.DataFrame:
    df = pd.read_csv(file, encoding="utf-8-sig")
    df = normalize_columns(df)

    df["ëŒ€ìƒì¼"] = pd.to_datetime(df["ëŒ€ìƒì¼"], errors="coerce")
    if df["ëŒ€ìƒì¼"].isna().any():
        raise ValueError("ëŒ€ìƒì¼ ì»¬ëŸ¼ì— ë³€í™˜í•  ìˆ˜ ì—†ëŠ” ê°’ì´ ìˆìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")

    for metric_col in ["ì¡°íšŒ ìˆ˜", "ìƒë‹´ì‹ ì²­ ìˆ˜"]:
        df[metric_col] = (
            pd.to_numeric(df[metric_col], errors="coerce")
            .fillna(0)
            .astype(int)
        )
    df["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"] = df["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"].astype(str)
    return df


def get_event_options(df: pd.DataFrame):
    options = (
        df[["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", "ì´ë²¤íŠ¸ ì´ë¦„"]]
        .drop_duplicates()
        .sort_values("ì´ë²¤íŠ¸ ì´ë¦„")
    )
    return list(options.itertuples(index=False, name=None))


def parse_event_ids_input(raw_text: str, valid_ids: set[str]):
    if not raw_text:
        return [], []
    tokens = [
        token.strip()
        for token in re.split(r"[,\n]+", raw_text)
        if token.strip()
    ]
    seen = []
    for token in tokens:
        if token not in seen:
            seen.append(token)
    invalid = [token for token in seen if token not in valid_ids]
    valid = [token for token in seen if token in valid_ids]
    return valid, invalid


def render_selected_events(selected_ids: list[str], event_lookup: dict[str, str]):
    if not selected_ids:
        st.info("ì„ íƒëœ ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    data = [
        {"ì´ë²¤íŠ¸ ID": event_id, "ì´ë²¤íŠ¸ ì´ë¦„": event_lookup.get(event_id, "ì•Œ ìˆ˜ ì—†ìŒ")}
        for event_id in selected_ids
    ]
    df = pd.DataFrame(data)
    with st.expander("ì„ íƒëœ ì´ë²¤íŠ¸ ëª©ë¡", expanded=False):
        st.dataframe(df, hide_index=True, use_container_width=True, height=240)


def get_date_range_input(df: pd.DataFrame):
    min_date = df["ëŒ€ìƒì¼"].min().date()
    max_date = df["ëŒ€ìƒì¼"].max().date()
    default_range = (min_date, max_date)
    selected = st.sidebar.date_input(
        "ë¶„ì„ ê¸°ê°„ (ì§„í–‰ ê¸°ê°„)",
        value=default_range,
        min_value=min_date,
        max_value=max_date,
    )
    if isinstance(selected, date):
        return selected, selected
    if isinstance(selected, (list, tuple)) and len(selected) == 2:
        return selected[0], selected[1]
    st.sidebar.error("ê¸°ê°„ì˜ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.")
    st.stop()


def filter_period(df: pd.DataFrame, start: pd.Timestamp, end: pd.Timestamp):
    mask = (df["ëŒ€ìƒì¼"] >= start) & (df["ëŒ€ìƒì¼"] <= end)
    return df.loc[mask].copy()


def build_event_summary(
    current_df: pd.DataFrame,
    previous_df: pd.DataFrame,
    event_lookup: dict[str, str],
) -> pd.DataFrame:
    metrics = ["ì¡°íšŒ ìˆ˜", "ìƒë‹´ì‹ ì²­ ìˆ˜"]
    summary = (
        current_df.groupby("ì´ë²¤íŠ¸ ID (ì‹ë³„ì)")[metrics]
        .sum()
        .reset_index()
        .rename(
            columns={
                metric: f"{metric} (ì§„í–‰ ê¸°ê°„)" for metric in metrics
            }
        )
    )
    previous = (
        previous_df.groupby("ì´ë²¤íŠ¸ ID (ì‹ë³„ì)")[metrics]
        .sum()
        .reset_index()
        .rename(
            columns={
                metric: f"{metric} (ì´ì „ ê¸°ê°„)" for metric in metrics
            }
        )
    )
    summary = summary.merge(previous, on="ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", how="outer").fillna(0)
    summary["ì´ë²¤íŠ¸ ì´ë¦„"] = summary["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"].map(event_lookup)

    for metric in metrics:
        current_col = f"{metric} (ì§„í–‰ ê¸°ê°„)"
        previous_col = f"{metric} (ì´ì „ ê¸°ê°„)"
        diff_col = f"{metric} Diff"
        summary[diff_col] = summary[current_col] - summary[previous_col]
        rate_col = f"{metric} ì¦ê°ë¥ "
        summary[rate_col] = np.where(
            summary[previous_col] > 0,
            summary[diff_col] / summary[previous_col] * 100,
            np.nan,
        )

    columns_order = [
        "ì´ë²¤íŠ¸ ì´ë¦„",
        "ì´ë²¤íŠ¸ ID (ì‹ë³„ì)",
        "ì¡°íšŒ ìˆ˜ (ì§„í–‰ ê¸°ê°„)",
        "ì¡°íšŒ ìˆ˜ (ì´ì „ ê¸°ê°„)",
        "ì¡°íšŒ ìˆ˜ Diff",
        "ì¡°íšŒ ìˆ˜ ì¦ê°ë¥ ",
        "ìƒë‹´ì‹ ì²­ ìˆ˜ (ì§„í–‰ ê¸°ê°„)",
        "ìƒë‹´ì‹ ì²­ ìˆ˜ (ì´ì „ ê¸°ê°„)",
        "ìƒë‹´ì‹ ì²­ ìˆ˜ Diff",
        "ìƒë‹´ì‹ ì²­ ìˆ˜ ì¦ê°ë¥ ",
    ]
    existing_columns = [col for col in columns_order if col in summary.columns]
    return summary[existing_columns].sort_values(
        "ìƒë‹´ì‹ ì²­ ìˆ˜ (ì§„í–‰ ê¸°ê°„)", ascending=False
    )


def generate_event_insights(summary_df: pd.DataFrame, top_n: int = 3) -> list[dict]:
    if summary_df.empty:
        return [
            {
                "title": "ë°ì´í„° ë¶€ì¡±",
                "badge": "Info",
                "items": ["ì„ íƒëœ ì´ë²¤íŠ¸ì— ëŒ€í•œ ë¹„êµ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."],
            }
        ]

    insights: list[dict] = []
    metrics = ["ì¡°íšŒ ìˆ˜", "ìƒë‹´ì‹ ì²­ ìˆ˜"]
    for metric in metrics:
        diff_col = f"{metric} Diff"
        if diff_col not in summary_df:
            continue
        positive = summary_df[summary_df[diff_col] > 0]

        if not positive.empty:
            top_positive = positive.sort_values(diff_col, ascending=False).head(top_n)
            items = [
                {
                    "label": row.get("ì´ë²¤íŠ¸ ì´ë¦„") or row["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"],
                    "value": f"+{int(row[diff_col]):,}ê±´",
                }
                for _, row in top_positive.iterrows()
            ]
            insights.append(
                {
                    "title": f"{metric} ìƒìŠ¹ TOP {len(items)}",
                    "badge": metric,
                    "items": items,
                }
            )


    if not insights:
        insights.append(
            {
                "title": "ë³€í™” ì—†ìŒ",
                "badge": "Info",
                "items": ["ë‘ ê¸°ê°„ ì‚¬ì´ì—ì„œ ëšœë ·í•œ ì¦ê°ì„ ë³´ì´ëŠ” ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."],
            }
        )
    return insights


def format_event_summary_display(summary_df: pd.DataFrame) -> pd.DataFrame:
    display_df = summary_df.copy()
    number_cols = [
        col
        for col in display_df.columns
        if (
            ("ì¡°íšŒ ìˆ˜" in col or "ìƒë‹´ì‹ ì²­ ìˆ˜" in col)
            and "ì¦ê°ë¥ " not in col
            and "ì „í™˜ìœ¨" not in col
        )
    ]
    rate_cols = [col for col in display_df.columns if "ì¦ê°ë¥ " in col]

    for col in number_cols:
        display_df[col] = display_df[col].apply(
            lambda x: f"{int(x):,}" if pd.notna(x) else "-"
        )
    for col in rate_cols:
        display_df[col] = display_df[col].apply(
            lambda x: f"{x:+.1f}%" if pd.notna(x) else "-"
        )
    return display_df


def render_insight_cards(insights: list[dict]):
    if not insights:
        st.info("í‘œì‹œí•  ì¸ì‚¬ì´íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    columns_count = min(3, len(insights))
    cols = st.columns(columns_count)
    card_template = dedent(
        """
        <div style="
            border-radius: 12px;
            padding: 16px;
            margin-bottom: 12px;
            background: linear-gradient(135deg, #eef2ff, #fef3c7);
            border: 1px solid #e5e7eb;
            box-shadow: 0 8px 20px rgba(15, 23, 42, 0.08);
        ">
            <div style="font-size:12px;font-weight:600;color:#6366f1;">{badge}</div>
            <div style="font-size:16px;font-weight:700;color:#111827;margin-top:4px;">{title}</div>
            <div style="margin-top:10px;">{items}</div>
        </div>
        """
    ).strip()
    item_template = dedent(
        """
        <div style="
            display:flex;
            justify-content:space-between;
            font-size:14px;
            color:#374151;
            padding:4px 0;
            border-bottom:1px dashed #e5e7eb;
        ">
            <span style="flex:1; margin-right:8px;">{label}</span>
            <span style="font-weight:600;color:#111827;">{value}</span>
        </div>
        """
    ).strip()
    for idx, insight in enumerate(insights):
        column = cols[idx % columns_count]
        with column:
            items = insight.get("items") or []
            rendered_items = []
            for item in items:
                if isinstance(item, dict):
                    label = item.get("label", "")
                    value = item.get("value", "")
                elif isinstance(item, str):
                    label, value = item, ""
                else:
                    label, value = str(item), ""
                label_safe = html.escape(str(label))
                value_safe = html.escape(str(value))
                rendered_items.append(
                    item_template.format(label=label_safe, value=value_safe)
                )
            badge_safe = html.escape(str(insight.get("badge", "")))
            title_safe = html.escape(str(insight.get("title", "")))
            st.markdown(
                card_template.format(
                    badge=badge_safe,
                    title=title_safe,
                    items="".join(rendered_items) or "<div>ë°ì´í„° ì—†ìŒ</div>",
                ),
                unsafe_allow_html=True,
            )


def build_timeseries_with_dates(df: pd.DataFrame, label: str):
    if df.empty:
        return pd.DataFrame(columns=["Day", "Date", "ìƒë‹´ì‹ ì²­ ìˆ˜", "ê¸°ê°„"])
    sorted_df = df.sort_values("ëŒ€ìƒì¼")
    day_offsets = (
        sorted_df["ëŒ€ìƒì¼"].values - sorted_df["ëŒ€ìƒì¼"].min().to_datetime64()
    ) / np.timedelta64(1, "D")
    sorted_df["Day"] = day_offsets.astype(int) + 1
    sorted_df["Date"] = sorted_df["ëŒ€ìƒì¼"].dt.date
    ts = (
        sorted_df.groupby(["Day", "Date"])["ìƒë‹´ì‹ ì²­ ìˆ˜"]
        .sum()
        .reset_index()
    )
    ts["ê¸°ê°„"] = label
    return ts


def render_metrics(current_df: pd.DataFrame, previous_df: pd.DataFrame):
    metrics = {
        "ì¡°íšŒ ìˆ˜": "ì¡°íšŒ ìˆ˜",
        "ìƒë‹´ì‹ ì²­ ìˆ˜": "ìƒë‹´ì‹ ì²­ ìˆ˜",
    }
    cols = st.columns(len(metrics))
    for idx, (label, column) in enumerate(metrics.items()):
        current_val = int(current_df[column].sum())
        previous_val = int(previous_df[column].sum()) if not previous_df.empty else None
        delta = None
        if previous_val is not None:
            delta_numeric = current_val - previous_val
            if previous_val == 0:
                delta = f"{delta_numeric:+,} (ì´ì „ ê¸°ê°„ 0)"
            else:
                delta_percentage = (delta_numeric / previous_val) * 100
                delta = f"{delta_numeric:+,} ({delta_percentage:+.1f}%)"
        cols[idx].metric(
            label,
            f"{current_val:,}",
            delta=delta or "ë¹„êµ ë°ì´í„° ì—†ìŒ",
        )


def render_chart(current_df: pd.DataFrame):
    chart_df = build_timeseries_with_dates(current_df, "ì§„í–‰ ê¸°ê°„")
    if chart_df.empty:
        st.info("ì°¨íŠ¸ë¥¼ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    chart_df["DayLabel"] = chart_df.apply(
        lambda row: f"Day {int(row['Day'])} ({row['Date']})", axis=1
    )
    fig = px.line(
        chart_df,
        x="DayLabel",
        y="ìƒë‹´ì‹ ì²­ ìˆ˜",
        markers=True,
        labels={"DayLabel": "ê²½ê³¼ ì¼ìˆ˜ (ë‚ ì§œ)", "ìƒë‹´ì‹ ì²­ ìˆ˜": "ìƒë‹´ì‹ ì²­ ìˆ˜"},
    )
    fig.update_layout(height=400, hovermode="x unified", showlegend=False)
    st.plotly_chart(fig, use_container_width=True)


st.title("ğŸ’œ CRMíŒ€ ê¸°íšì „ ì„±ê³¼ ë¶„ì„")
st.markdown(
    """
í€µì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œ([ë§í¬](https://ap-northeast-2.quicksight.aws.amazon.com/sn/account/babitalk-data-quicksight/dashboards/74afc507-059e-421c-910d-303f57ae1900/sheets/74afc507-059e-421c-910d-303f57ae1900_26f4f316-a3a6-4f09-9797-708c736937d5))ì—ì„œ CSVë¥¼ ë‚´ë ¤ë°›ì•„ ì´ í˜ì´ì§€ì— ì—…ë¡œë“œí•œ ë’¤, ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  ì´ë²¤íŠ¸ IDì™€ ë¶„ì„ ê¸°ê°„(ê¸°íšì „ ì§„í–‰ê¸°ê°„)ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. í€µì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œì—ì„œ [ëŒ€ìƒì¼ - descending]ì„ ì„ íƒí•´ì„œ ë‚´ë ¤ë°›ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤. (ì•½ ìµœê·¼ 6ê°œì›” ì»¤ë²„ ê°€ëŠ¥) ì´ í˜ì´ì§€ì— ë¬¸ì œê°€ ìƒê¸°ë©´ CRMíŒ€ **@ê¹€ì˜ˆìŠ¬** ì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.
"""
)

uploaded_file = st.file_uploader("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["csv"])
if uploaded_file is None:
    st.info("ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.stop()

try:
    df = load_data(uploaded_file)
except ValueError as exc:
    st.error(str(exc))
    st.stop()
except Exception as exc:  # noqa: BLE001
    st.error(f"ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
    st.stop()

st.sidebar.header("ë¶„ì„ ì„¤ì •")
event_options = get_event_options(df)
if not event_options:
    st.error("ì´ë²¤íŠ¸ ì •ë³´ê°€ í¬í•¨ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

event_lookup = {event_id: event_name for event_id, event_name in event_options}
available_ids = list(event_lookup.keys())

with st.sidebar.expander("ì´ë²¤íŠ¸ ID ëª©ë¡ ë³´ê¸°"):
    st.dataframe(
        pd.DataFrame(event_options, columns=["ì´ë²¤íŠ¸ ID", "ì´ë²¤íŠ¸ ì´ë¦„"]),
        use_container_width=True,
    )

default_event_input = available_ids[0] if available_ids else ""
event_input = st.sidebar.text_area(
    "ë¶„ì„í•  ì´ë²¤íŠ¸ ID (ì¤„ë°”ê¿ˆ ë˜ëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„)",
    value=default_event_input,
    height=120,
    placeholder="ì˜ˆ: 53004\\n47917",
)
selected_event_ids, invalid_event_ids = parse_event_ids_input(
    event_input,
    set(available_ids),
)

if invalid_event_ids:
    st.sidebar.error(
        f"ë‹¤ìŒ ì´ë²¤íŠ¸ IDëŠ” ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤: {', '.join(invalid_event_ids)}"
    )
    st.stop()

if not selected_event_ids:
    st.sidebar.error("ìµœì†Œ í•œ ê°œì˜ ì´ë²¤íŠ¸ IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

event_df = df[df["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"].isin(selected_event_ids)].copy()

if event_df.empty:
    st.error("ì„ íƒí•œ ì´ë²¤íŠ¸ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

start_date, end_date = get_date_range_input(event_df)

if start_date > end_date:
    st.sidebar.error("ì‹œì‘ì¼ì€ ì¢…ë£Œì¼ë³´ë‹¤ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()

current_start = pd.Timestamp(start_date)
current_end = pd.Timestamp(end_date)
period_days = (current_end - current_start).days + 1
if period_days <= 0:
    st.sidebar.error("ë¶„ì„ ê¸°ê°„ì€ ìµœì†Œ í•˜ë£¨ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()

current_period_df = filter_period(event_df, current_start, current_end)
previous_end = current_start - timedelta(days=1)
previous_start = previous_end - timedelta(days=period_days - 1)
previous_period_df = filter_period(event_df, previous_start, previous_end)

st.subheader(f"ì„ íƒëœ ì´ë²¤íŠ¸ ({len(selected_event_ids)}ê°œ)")
render_selected_events(selected_event_ids, event_lookup)
st.caption(
    f"ì§„í–‰ ê¸°ê°„: {current_start.date()} ~ {current_end.date()} | "
    f"ì´ì „ ê¸°ê°„: {previous_start.date()} ~ {previous_end.date()} "
    f"(ì´ {period_days}ì¼)"
)

if current_period_df.empty:
    st.warning("ì„ íƒëœ ê¸°ê°„ ë‚´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê¸°ê°„ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    st.stop()

render_metrics(current_period_df, previous_period_df)

event_summary_df = build_event_summary(
    current_period_df, previous_period_df, event_lookup
)
event_insights = generate_event_insights(event_summary_df)
event_summary_display = format_event_summary_display(event_summary_df)

tab_insight, tab_trend = st.tabs(
    ["ğŸ’¡ ì´ë²¤íŠ¸ ì¸ì‚¬ì´íŠ¸", "ğŸ“ˆ ê¸°ê°„ë³„ ì¶”ì´"]
)

with tab_insight:
    st.markdown("#### ì´ë²¤íŠ¸ ì„±ê³¼ í•˜ì´ë¼ì´íŠ¸")
    render_insight_cards(event_insights)
    if not event_summary_df.empty:
        st.markdown("##### ì´ë²¤íŠ¸ë³„ ìƒì„¸ ì§€í‘œ")
        st.dataframe(
            event_summary_display,
            use_container_width=True,
            hide_index=True,
        )
    else:
        st.info("ì´ë²¤íŠ¸ë³„ ì„¸ë¶€ ì§€í‘œë¥¼ ê³„ì‚°í•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

with tab_trend:
    st.markdown("#### ê¸°ê°„ë³„ ìƒë‹´ì‹ ì²­ ìˆ˜ ì¶”ì´")
    render_chart(current_period_df)

with st.expander("ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
    st.dataframe(event_df.sort_values("ëŒ€ìƒì¼"), use_container_width=True)

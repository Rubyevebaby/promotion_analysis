import html
import re
from datetime import date, timedelta
from textwrap import dedent

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st

st.set_page_config(
    page_title="CRMíŒ€ ê¸°íšì „ ì„±ê³¼ ë¶„ì„",
    layout="wide",
    page_icon="Symbol.png",
)

REQUIRED_COLUMNS = [
    "ë³‘ì› ID",
    "ë³‘ì› ì´ë¦„",
    "ëŒ€í–‰ì‚¬ ID",
    "ëŒ€í–‰ì‚¬ ì´ë¦„",
    "ì´ë²¤íŠ¸ ID (ì‹ë³„ì)",
    "ì´ë²¤íŠ¸ ì´ë¦„",
    "ì´ë²¤íŠ¸ ê°€ê²© (text)",
    "ì¹´í…Œê³ ë¦¬ (ìµœìƒìœ„)",
    "ì¹´í…Œê³ ë¦¬ (ëŒ€)",
    "ì¹´í…Œê³ ë¦¬ (ì¤‘)",
    "ì¹´í…Œê³ ë¦¬ (ì†Œ)",
    "ëŒ€ìƒì¼",
    "ì¡°íšŒ ìˆ˜",
    "ìƒë‹´ì‹ ì²­ ìˆ˜",
]

COLUMN_ALIASES = {
    "ì´ë²¤íŠ¸ ID (ì‹ë³„ì)": ["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", "ì´ë²¤íŠ¸ ID"],
    "ë³‘ì› ì´ë¦„": ["ë³‘ì› ì´ë¦„", "ë³‘ì›ëª…"],
}

CPV_REQUIRED_COLUMNS = [
    "ë³‘ì› ID",
    "ë³‘ì› ì´ë¦„",
    "ì´ë²¤íŠ¸ ID (ì‹ë³„ì)",
    "ì´ë²¤íŠ¸ ì´ë¦„",
    "ëŒ€ìƒì¼",
    "CPV ì¡°íšŒ ìˆ˜",
    "CPV ë§¤ì¶œ",
]

CPV_COLUMN_ALIASES = {
    "ì´ë²¤íŠ¸ ID (ì‹ë³„ì)": ["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", "ì´ë²¤íŠ¸ ID"],
    "ë³‘ì› ì´ë¦„": ["ë³‘ì› ì´ë¦„", "ë³‘ì›ëª…"],
    "ì´ë²¤íŠ¸ ì´ë¦„": ["ì´ë²¤íŠ¸ ì´ë¦„", "ì´ë²¤íŠ¸ëª…"],
    "CPV ì¡°íšŒ ìˆ˜": ["CPV ì¡°íšŒ ìˆ˜"],
    "CPV ë§¤ì¶œ": ["CPV ë§¤ì¶œ"],
}


def normalize_columns(
    df: pd.DataFrame,
    required_columns: list[str],
    aliases: dict[str, list[str]],
) -> pd.DataFrame:
    rename_map = {}
    missing = []
    for required in required_columns:
        candidates = aliases.get(required, [required])
        matched = next((c for c in candidates if c in df.columns), None)
        if matched:
            rename_map[matched] = required
        else:
            missing.append(required)
    if missing:
        raise ValueError(f"ë‹¤ìŒ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing)}")
    return df.rename(columns=rename_map)


@st.cache_data(show_spinner=True)
def load_data(file) -> pd.DataFrame:
    df = pd.read_csv(file, encoding="utf-8-sig")
    df = normalize_columns(df, REQUIRED_COLUMNS, COLUMN_ALIASES)

    df["ëŒ€ìƒì¼"] = pd.to_datetime(df["ëŒ€ìƒì¼"], errors="coerce")
    if df["ëŒ€ìƒì¼"].isna().any():
        raise ValueError("ëŒ€ìƒì¼ ì»¬ëŸ¼ì— ë³€í™˜í•  ìˆ˜ ì—†ëŠ” ê°’ì´ ìˆìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")

    for metric_col in ["ì¡°íšŒ ìˆ˜", "ìƒë‹´ì‹ ì²­ ìˆ˜"]:
        df[metric_col] = (
            pd.to_numeric(df[metric_col], errors="coerce")
            .fillna(0)
            .astype(int)
        )
    df["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"] = df["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"].astype(str)
    return df


@st.cache_data(show_spinner=True)
def load_cpv_data(file) -> pd.DataFrame:
    df = pd.read_csv(file, encoding="utf-8-sig")
    df = normalize_columns(df, CPV_REQUIRED_COLUMNS, CPV_COLUMN_ALIASES)
    df["ëŒ€ìƒì¼"] = pd.to_datetime(df["ëŒ€ìƒì¼"], errors="coerce")
    if df["ëŒ€ìƒì¼"].isna().any():
        raise ValueError("CPV ë°ì´í„°ì˜ ëŒ€ìƒì¼ ì»¬ëŸ¼ì— ë³€í™˜í•  ìˆ˜ ì—†ëŠ” ê°’ì´ ìˆìŠµë‹ˆë‹¤.")
    for metric_col in ["CPV ì¡°íšŒ ìˆ˜", "CPV ë§¤ì¶œ"]:
        df[metric_col] = (
            pd.to_numeric(df[metric_col], errors="coerce").fillna(0).astype(int)
        )
    df["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"] = df["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"].astype(str)
    return df


def get_event_options(df: pd.DataFrame):
    options = (
        df[["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", "ì´ë²¤íŠ¸ ì´ë¦„"]]
        .drop_duplicates()
        .sort_values("ì´ë²¤íŠ¸ ì´ë¦„")
    )
    return list(options.itertuples(index=False, name=None))


def parse_event_ids_input(raw_text: str, valid_ids: set[str]):
    if not raw_text:
        return [], []
    tokens = [
        token.strip()
        for token in re.split(r"[,\n]+", raw_text)
        if token.strip()
    ]
    seen = []
    for token in tokens:
        if token not in seen:
            seen.append(token)
    invalid = [token for token in seen if token not in valid_ids]
    valid = [token for token in seen if token in valid_ids]
    return valid, invalid


def render_selected_events(selected_ids: list[str], event_lookup: dict[str, str]):
    if not selected_ids:
        st.info("ì„ íƒëœ ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    data = [
        {"ì´ë²¤íŠ¸ ID": event_id, "ì´ë²¤íŠ¸ ì´ë¦„": event_lookup.get(event_id, "ì•Œ ìˆ˜ ì—†ìŒ")}
        for event_id in selected_ids
    ]
    df = pd.DataFrame(data)
    with st.expander("ì„ íƒëœ ì´ë²¤íŠ¸ ëª©ë¡", expanded=False):
        st.dataframe(df, hide_index=True, use_container_width=True, height=240)


def get_date_range_input(df: pd.DataFrame):
    min_date = df["ëŒ€ìƒì¼"].min().date()
    max_date = df["ëŒ€ìƒì¼"].max().date()
    default_range = (min_date, max_date)
    selected = st.sidebar.date_input(
        "ë¶„ì„ ê¸°ê°„ (ì§„í–‰ ê¸°ê°„)",
        value=default_range,
        min_value=min_date,
        max_value=max_date,
    )
    if isinstance(selected, date):
        return selected, selected
    if isinstance(selected, (list, tuple)) and len(selected) == 2:
        return selected[0], selected[1]
    st.sidebar.error("ê¸°ê°„ì˜ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.")
    st.stop()


def filter_period(df: pd.DataFrame, start: pd.Timestamp, end: pd.Timestamp):
    mask = (df["ëŒ€ìƒì¼"] >= start) & (df["ëŒ€ìƒì¼"] <= end)
    return df.loc[mask].copy()


def build_event_summary(
    current_df: pd.DataFrame,
    previous_df: pd.DataFrame,
    cpv_current_df: pd.DataFrame,
    cpv_previous_df: pd.DataFrame,
    event_lookup: dict[str, str],
) -> pd.DataFrame:
    metrics = ["ì¡°íšŒ ìˆ˜", "ìƒë‹´ì‹ ì²­ ìˆ˜"]
    hospital_sources = [
        current_df[["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", "ë³‘ì› ì´ë¦„"]],
        previous_df[["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", "ë³‘ì› ì´ë¦„"]],
        cpv_current_df[["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", "ë³‘ì› ì´ë¦„"]],
        cpv_previous_df[["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", "ë³‘ì› ì´ë¦„"]],
    ]
    hospital_info = (
        pd.concat(hospital_sources, ignore_index=True)
        .dropna(subset=["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"])
        .drop_duplicates(subset=["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"])
    )
    id_sources = [
        current_df["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"],
        previous_df["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"],
        cpv_current_df["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"],
        cpv_previous_df["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"],
    ]
    combined_ids = (
        pd.concat(id_sources, ignore_index=True)
        .dropna()
        .astype(str)
        .unique()
    )
    summary = pd.DataFrame({"ì´ë²¤íŠ¸ ID (ì‹ë³„ì)": combined_ids})
    if summary.empty:
        return summary

    current = (
        current_df.groupby("ì´ë²¤íŠ¸ ID (ì‹ë³„ì)")[metrics]
        .sum()
        .reset_index()
        .rename(
            columns={
                metric: f"{metric} (ì§„í–‰ ê¸°ê°„)" for metric in metrics
            }
        )
    )
    previous = (
        previous_df.groupby("ì´ë²¤íŠ¸ ID (ì‹ë³„ì)")[metrics]
        .sum()
        .reset_index()
        .rename(
            columns={
                metric: f"{metric} (ì´ì „ ê¸°ê°„)" for metric in metrics
            }
        )
    )
    summary = summary.merge(current, on="ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", how="left")
    summary = summary.merge(previous, on="ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", how="left")
    summary["ì´ë²¤íŠ¸ ì´ë¦„"] = summary["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"].map(event_lookup)
    summary = summary.merge(hospital_info, on="ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", how="left")

    cpv_metrics = ["CPV ì¡°íšŒ ìˆ˜", "CPV ë§¤ì¶œ"]
    cpv_current = (
        cpv_current_df.groupby("ì´ë²¤íŠ¸ ID (ì‹ë³„ì)")[cpv_metrics]
        .sum()
        .reset_index()
        .rename(columns={metric: f"{metric} (ì§„í–‰ ê¸°ê°„)" for metric in cpv_metrics})
    )
    cpv_previous = (
        cpv_previous_df.groupby("ì´ë²¤íŠ¸ ID (ì‹ë³„ì)")[cpv_metrics]
        .sum()
        .reset_index()
        .rename(columns={metric: f"{metric} (ì´ì „ ê¸°ê°„)" for metric in cpv_metrics})
    )
    summary = summary.merge(cpv_current, on="ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", how="left")
    summary = summary.merge(cpv_previous, on="ì´ë²¤íŠ¸ ID (ì‹ë³„ì)", how="left")

    all_metrics = metrics + cpv_metrics
    for metric in all_metrics:
        for period in ["ì§„í–‰ ê¸°ê°„", "ì´ì „ ê¸°ê°„"]:
            col = f"{metric} ({period})"
            if col not in summary:
                summary[col] = 0
            else:
                summary[col] = summary[col].fillna(0)
        current_col = f"{metric} (ì§„í–‰ ê¸°ê°„)"
        previous_col = f"{metric} (ì´ì „ ê¸°ê°„)"
        diff_col = f"{metric} ì¦ê°ëŸ‰"
        summary[diff_col] = summary[current_col] - summary[previous_col]
        rate_col = f"{metric} ì¦ê°ë¥ "
        summary[rate_col] = np.where(
            summary[previous_col] > 0,
            summary[diff_col] / summary[previous_col] * 100,
            np.nan,
        )

    columns_order = [
        "ì´ë²¤íŠ¸ ì´ë¦„",
        "ë³‘ì› ì´ë¦„",
        "ì´ë²¤íŠ¸ ID (ì‹ë³„ì)",
        "ì¡°íšŒ ìˆ˜ (ì§„í–‰ ê¸°ê°„)",
        "ì¡°íšŒ ìˆ˜ (ì´ì „ ê¸°ê°„)",
        "ì¡°íšŒ ìˆ˜ ì¦ê°ëŸ‰",
        "ì¡°íšŒ ìˆ˜ ì¦ê°ë¥ ",
        "ìƒë‹´ì‹ ì²­ ìˆ˜ (ì§„í–‰ ê¸°ê°„)",
        "ìƒë‹´ì‹ ì²­ ìˆ˜ (ì´ì „ ê¸°ê°„)",
        "ìƒë‹´ì‹ ì²­ ìˆ˜ ì¦ê°ëŸ‰",
        "ìƒë‹´ì‹ ì²­ ìˆ˜ ì¦ê°ë¥ ",
        "CPV ë§¤ì¶œ (ì§„í–‰ ê¸°ê°„)",
        "CPV ë§¤ì¶œ (ì´ì „ ê¸°ê°„)",
        "CPV ë§¤ì¶œ ì¦ê°ëŸ‰",
        "CPV ë§¤ì¶œ ì¦ê°ë¥ ",
    ]
    existing_columns = [col for col in columns_order if col in summary.columns]
    return summary[existing_columns].sort_values(
        "ìƒë‹´ì‹ ì²­ ìˆ˜ (ì§„í–‰ ê¸°ê°„)", ascending=False
    )


def generate_event_insights(summary_df: pd.DataFrame, top_n: int = 3) -> list[dict]:
    if summary_df.empty:
        return [
            {
                "title": "ë°ì´í„° ë¶€ì¡±",
                "badge": "Info",
                "items": ["ì„ íƒëœ ì´ë²¤íŠ¸ì— ëŒ€í•œ ë¹„êµ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."],
            }
        ]

    insights: list[dict] = []
    metrics = ["ì¡°íšŒ ìˆ˜", "ìƒë‹´ì‹ ì²­ ìˆ˜", "CPV ë§¤ì¶œ"]
    for metric in metrics:
        diff_col = f"{metric} ì¦ê°ëŸ‰"
        diff_rate_col = f"{metric} ì¦ê°ë¥ "
        if diff_col not in summary_df:
            continue
        positive = summary_df[summary_df[diff_col] > 0]

        if not positive.empty:
            top_positive = positive.sort_values(diff_col, ascending=False).head(top_n)
            unit = "ì›" if "ë§¤ì¶œ" in metric else "ê±´"
            items = [
                {
                    "label": row.get("ì´ë²¤íŠ¸ ì´ë¦„") or row["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"],
                    "value": f"+{int(row[diff_col]):,}{unit}",
                }
                for _, row in top_positive.iterrows()
            ]
            insights.append(
                {
                    "title": f"{metric} ìƒìŠ¹ TOP {len(items)}",
                    "badge": metric,
                    "items": items,
                }
            )

        if metric == "CPV ë§¤ì¶œ" and diff_rate_col in summary_df:
            positive_rate = summary_df[summary_df[diff_rate_col] > 0]
            if not positive_rate.empty:
                top_rate = positive_rate.sort_values(
                    diff_rate_col, ascending=False
                ).head(top_n)
                items_rate = [
                    {
                        "label": row.get("ì´ë²¤íŠ¸ ì´ë¦„") or row["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"],
                        "value": f"+{row[diff_rate_col]:.1f}%",
                    }
                    for _, row in top_rate.iterrows()
                ]
                insights.append(
                    {
                        "title": f"{metric} ì¦ê°ë¥  TOP {len(items_rate)}",
                        "badge": f"{metric} ì¦ê°ë¥ ",
                        "items": items_rate,
                    }
                )


    if not insights:
        insights.append(
            {
                "title": "ë³€í™” ì—†ìŒ",
                "badge": "Info",
                "items": ["ë‘ ê¸°ê°„ ì‚¬ì´ì—ì„œ ëšœë ·í•œ ì¦ê°ì„ ë³´ì´ëŠ” ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."],
            }
        )
    return insights


def format_event_summary_display(summary_df: pd.DataFrame) -> pd.DataFrame:
    display_df = summary_df.copy()
    number_cols = [
        col
        for col in display_df.columns
        if (
            ("ì¡°íšŒ ìˆ˜" in col or "ìƒë‹´ì‹ ì²­ ìˆ˜" in col or "CPV ë§¤ì¶œ" in col)
            and "ì¦ê°ë¥ " not in col
        )
    ]
    rate_cols = [col for col in display_df.columns if "ì¦ê°ë¥ " in col]

    for col in number_cols:
        display_df[col] = display_df[col].apply(
            lambda x: f"{int(x):,}" if pd.notna(x) and x != 0 else "-"
        )
    for col in rate_cols:
        display_df[col] = display_df[col].apply(
            lambda x: f"{x:+.1f}%" if pd.notna(x) else "-"
        )
    return display_df


def render_insight_cards(insights: list[dict]):
    if not insights:
        st.info("í‘œì‹œí•  ì¸ì‚¬ì´íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    columns_per_row = min(2, len(insights))
    card_template = dedent(
        """
        <div style="
            border-radius: 12px;
            padding: 16px;
            margin-bottom: 12px;
            background: linear-gradient(135deg, #eef2ff, #fef3c7);
            border: 1px solid #e5e7eb;
            box-shadow: 0 8px 20px rgba(15, 23, 42, 0.08);
        ">
            <div style="font-size:12px;font-weight:600;color:#6366f1;">{badge}</div>
            <div style="font-size:16px;font-weight:700;color:#111827;margin-top:4px;">{title}</div>
            <div style="margin-top:10px;">{items}</div>
        </div>
        """
    ).strip()
    item_template = dedent(
        """
        <div style="
            display:flex;
            justify-content:space-between;
            font-size:14px;
            color:#374151;
            padding:4px 0;
            border-bottom:1px dashed #e5e7eb;
        ">
            <span style="flex:1; margin-right:8px;">{label}</span>
            <span style="font-weight:600;color:#111827;">{value}</span>
        </div>
        """
    ).strip()
    for start in range(0, len(insights), columns_per_row):
        cols = st.columns(columns_per_row)
        row_insights = insights[start : start + columns_per_row]
        for idx, insight in enumerate(row_insights):
            items = insight.get("items") or []
            rendered_items = []
            for item in items:
                if isinstance(item, dict):
                    label = item.get("label", "")
                    value = item.get("value", "")
                elif isinstance(item, str):
                    label, value = item, ""
                else:
                    label, value = str(item), ""
                label_safe = html.escape(str(label))
                value_safe = html.escape(str(value))
                rendered_items.append(
                    item_template.format(label=label_safe, value=value_safe)
                )
            badge_safe = html.escape(str(insight.get("badge", "")))
            title_safe = html.escape(str(insight.get("title", "")))
            with cols[idx]:
                st.markdown(
                    card_template.format(
                        badge=badge_safe,
                        title=title_safe,
                        items="".join(rendered_items) or "<div>ë°ì´í„° ì—†ìŒ</div>",
                    ),
                    unsafe_allow_html=True,
                )


def build_timeseries_with_dates(df: pd.DataFrame, label: str):
    if df.empty:
        return pd.DataFrame(columns=["Day", "Date", "ìƒë‹´ì‹ ì²­ ìˆ˜", "ê¸°ê°„"])
    sorted_df = df.sort_values("ëŒ€ìƒì¼")
    day_offsets = (
        sorted_df["ëŒ€ìƒì¼"].values - sorted_df["ëŒ€ìƒì¼"].min().to_datetime64()
    ) / np.timedelta64(1, "D")
    sorted_df["Day"] = day_offsets.astype(int) + 1
    sorted_df["Date"] = sorted_df["ëŒ€ìƒì¼"].dt.date
    ts = (
        sorted_df.groupby(["Day", "Date"])["ìƒë‹´ì‹ ì²­ ìˆ˜"]
        .sum()
        .reset_index()
    )
    ts["ê¸°ê°„"] = label
    return ts


def render_metrics(metric_rows: list[dict]):
    if not metric_rows:
        return
    cols = st.columns(len(metric_rows))
    for idx, metric in enumerate(metric_rows):
        label = metric["label"]
        current_raw = metric.get("current")
        previous_raw = metric.get("previous")

        current_display = "-"
        delta = None

        if current_raw is not None:
            current_val = int(current_raw)
            current_display = f"{current_val:,}"

        if current_raw is not None and previous_raw is not None:
            previous_val = int(previous_raw)
            delta_numeric = current_val - previous_val
            if previous_val == 0:
                delta = f"{delta_numeric:+,} (ì´ì „ ê¸°ê°„ 0)"
            else:
                delta_percentage = (delta_numeric / previous_val) * 100
                delta = f"{delta_numeric:+,} ({delta_percentage:+.1f}%)"

        cols[idx].metric(
            label,
            current_display,
            delta=delta or "ë¹„êµ ë°ì´í„° ì—†ìŒ",
        )


def render_chart(current_df: pd.DataFrame):
    chart_df = build_timeseries_with_dates(current_df, "ì§„í–‰ ê¸°ê°„")
    if chart_df.empty:
        st.info("ì°¨íŠ¸ë¥¼ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    chart_df["DayLabel"] = chart_df.apply(
        lambda row: f"Day {int(row['Day'])} ({row['Date']})", axis=1
    )
    fig = px.line(
        chart_df,
        x="DayLabel",
        y="ìƒë‹´ì‹ ì²­ ìˆ˜",
        markers=True,
        labels={"DayLabel": "ê²½ê³¼ ì¼ìˆ˜ (ë‚ ì§œ)", "ìƒë‹´ì‹ ì²­ ìˆ˜": "ìƒë‹´ì‹ ì²­ ìˆ˜"},
    )
    fig.update_layout(height=400, hovermode="x unified", showlegend=False)
    st.plotly_chart(fig, use_container_width=True)


st.title("ğŸ’œ CRMíŒ€ ê¸°íšì „ ì„±ê³¼ ë¶„ì„")
st.markdown(
    """
í€µì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œ([ë§í¬](https://ap-northeast-2.quicksight.aws.amazon.com/sn/account/babitalk-data-quicksight/dashboards/74afc507-059e-421c-910d-303f57ae1900/sheets/74afc507-059e-421c-910d-303f57ae1900_26f4f316-a3a6-4f09-9797-708c736937d5))ì—ì„œ ì¡°íšŒ/ìƒë‹´ CSVì™€ CPV CSVë¥¼ ë‚´ë ¤ë°›ì•„ ì´ í˜ì´ì§€ì— ì—…ë¡œë“œí•œ ë’¤, ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  ì´ë²¤íŠ¸ IDì™€ ë¶„ì„ ê¸°ê°„(ê¸°íšì „ ì§„í–‰ê¸°ê°„)ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. í€µì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œì—ì„œ [ëŒ€ìƒì¼ - descending]ì„ ì„ íƒí•´ì„œ ë‚´ë ¤ë°›ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤. (ì•½ ìµœê·¼ 6ê°œì›” ì»¤ë²„ ê°€ëŠ¥) ì´ í˜ì´ì§€ì— ë¬¸ì œê°€ ìƒê¸°ë©´ CRMíŒ€ **@ê¹€ì˜ˆìŠ¬** ì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.
"""
)

uploaded_file = st.file_uploader(
    "ì¡°íšŒ/ìƒë‹´ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["csv"], key="primary_csv"
)
cpv_uploaded_file = st.file_uploader(
    "CPV CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["csv"], key="cpv_csv"
)

if uploaded_file is None and cpv_uploaded_file is None:
    st.info("ì¡°íšŒ/ìƒë‹´ CSV ë˜ëŠ” CPV CSV ì¤‘ ìµœì†Œ í•˜ë‚˜ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.stop()

try:
    df = (
        load_data(uploaded_file)
        if uploaded_file
        else pd.DataFrame(columns=REQUIRED_COLUMNS)
    )
except ValueError as exc:
    st.error(str(exc))
    st.stop()
except Exception as exc:  # noqa: BLE001
    st.error(f"ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
    st.stop()

if uploaded_file is None:
    st.warning("ì¡°íšŒ/ìƒë‹´ CSVê°€ ì—†ìœ¼ë©´ ì¡°íšŒ ìˆ˜ ë° ìƒë‹´ì‹ ì²­ ì§€í‘œëŠ” ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

try:
    cpv_df = (
        load_cpv_data(cpv_uploaded_file)
        if cpv_uploaded_file
        else pd.DataFrame(columns=CPV_REQUIRED_COLUMNS)
    )
except ValueError as exc:
    st.error(str(exc))
    st.stop()
except Exception as exc:  # noqa: BLE001
    st.error(f"CPV ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
    st.stop()

if cpv_uploaded_file is None:
    st.info("CPV CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ CPV ë§¤ì¶œ ë¶„ì„ì„ í•¨ê»˜ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

combined_df = pd.concat([df, cpv_df], ignore_index=True)

st.sidebar.header("ë¶„ì„ ì„¤ì •")
event_options = get_event_options(combined_df)
if not event_options:
    st.error("ì´ë²¤íŠ¸ ì •ë³´ê°€ í¬í•¨ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

event_lookup = {event_id: event_name for event_id, event_name in event_options}
available_ids = list(event_lookup.keys())

with st.sidebar.expander("ì´ë²¤íŠ¸ ID ëª©ë¡ ë³´ê¸°"):
    st.dataframe(
        pd.DataFrame(event_options, columns=["ì´ë²¤íŠ¸ ID", "ì´ë²¤íŠ¸ ì´ë¦„"]),
        use_container_width=True,
    )

default_event_input = available_ids[0] if available_ids else ""
event_input = st.sidebar.text_area(
    "ë¶„ì„í•  ì´ë²¤íŠ¸ ID (ì¤„ë°”ê¿ˆ ë˜ëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„)",
    value=default_event_input,
    height=120,
    placeholder="ì˜ˆ: 53004\\n47917",
)
selected_event_ids, invalid_event_ids = parse_event_ids_input(
    event_input,
    set(available_ids),
)

if invalid_event_ids:
    st.sidebar.error(
        f"ë‹¤ìŒ ì´ë²¤íŠ¸ IDëŠ” ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤: {', '.join(invalid_event_ids)}"
    )
    st.stop()

if not selected_event_ids:
    st.sidebar.error("ìµœì†Œ í•œ ê°œì˜ ì´ë²¤íŠ¸ IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

event_df = df[df["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"].isin(selected_event_ids)].copy()
cpv_event_df = cpv_df[cpv_df["ì´ë²¤íŠ¸ ID (ì‹ë³„ì)"].isin(selected_event_ids)].copy()

if event_df.empty and cpv_event_df.empty:
    st.error("ì„ íƒí•œ ì´ë²¤íŠ¸ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

if event_df.empty:
    st.warning("ì„ íƒí•œ ì´ë²¤íŠ¸ì— ëŒ€í•œ ì¡°íšŒ/ìƒë‹´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
if cpv_event_df.empty:
    st.warning("ì„ íƒí•œ ì´ë²¤íŠ¸ì— ëŒ€í•œ CPV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

date_input_df = event_df if not event_df.empty else cpv_event_df
start_date, end_date = get_date_range_input(date_input_df)

if start_date > end_date:
    st.sidebar.error("ì‹œì‘ì¼ì€ ì¢…ë£Œì¼ë³´ë‹¤ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()

current_start = pd.Timestamp(start_date)
current_end = pd.Timestamp(end_date)
period_days = (current_end - current_start).days + 1
if period_days <= 0:
    st.sidebar.error("ë¶„ì„ ê¸°ê°„ì€ ìµœì†Œ í•˜ë£¨ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()

current_period_df = filter_period(event_df, current_start, current_end)
previous_end = current_start - timedelta(days=1)
previous_start = previous_end - timedelta(days=period_days - 1)
previous_period_df = filter_period(event_df, previous_start, previous_end)
cpv_current_period_df = filter_period(cpv_event_df, current_start, current_end)
cpv_previous_period_df = filter_period(cpv_event_df, previous_start, previous_end)

st.subheader(f"ì„ íƒëœ ì´ë²¤íŠ¸ ({len(selected_event_ids)}ê°œ)")
render_selected_events(selected_event_ids, event_lookup)
st.caption(
    f"ì§„í–‰ ê¸°ê°„: {current_start.date()} ~ {current_end.date()} | "
    f"ì´ì „ ê¸°ê°„: {previous_start.date()} ~ {previous_end.date()} "
    f"(ì´ {period_days}ì¼)"
)

if current_period_df.empty and cpv_current_period_df.empty:
    st.warning("ì„ íƒëœ ê¸°ê°„ ë‚´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê¸°ê°„ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    st.stop()


def _metric_sum(df: pd.DataFrame, column: str) -> int:
    if df.empty or column not in df or df[column].dropna().empty:
        return None
    return int(df[column].sum())


metric_rows = [
    {
        "label": "ì¡°íšŒ ìˆ˜",
        "current": _metric_sum(current_period_df, "ì¡°íšŒ ìˆ˜"),
        "previous": _metric_sum(previous_period_df, "ì¡°íšŒ ìˆ˜")
        if not previous_period_df.empty
        else None,
    },
    {
        "label": "ìƒë‹´ì‹ ì²­ ìˆ˜",
        "current": _metric_sum(current_period_df, "ìƒë‹´ì‹ ì²­ ìˆ˜"),
        "previous": _metric_sum(previous_period_df, "ìƒë‹´ì‹ ì²­ ìˆ˜")
        if not previous_period_df.empty
        else None,
    },
    {
        "label": "CPV ì¡°íšŒ ìˆ˜",
        "current": _metric_sum(cpv_current_period_df, "CPV ì¡°íšŒ ìˆ˜"),
        "previous": _metric_sum(cpv_previous_period_df, "CPV ì¡°íšŒ ìˆ˜")
        if not cpv_previous_period_df.empty
        else None,
    },
    {
        "label": "CPV ë§¤ì¶œ",
        "current": _metric_sum(cpv_current_period_df, "CPV ë§¤ì¶œ"),
        "previous": _metric_sum(cpv_previous_period_df, "CPV ë§¤ì¶œ")
        if not cpv_previous_period_df.empty
        else None,
    },
]

render_metrics(metric_rows)

event_summary_df = build_event_summary(
    current_period_df,
    previous_period_df,
    cpv_current_period_df,
    cpv_previous_period_df,
    event_lookup,
)
event_insights = generate_event_insights(event_summary_df)
event_summary_display = format_event_summary_display(event_summary_df)

tab_insight, tab_trend = st.tabs(
    ["ğŸ’¡ ì´ë²¤íŠ¸ ì¸ì‚¬ì´íŠ¸", "ğŸ“ˆ ê¸°ê°„ë³„ ì¶”ì´"]
)

with tab_insight:
    st.markdown("#### ì´ë²¤íŠ¸ ì„±ê³¼ í•˜ì´ë¼ì´íŠ¸")
    render_insight_cards(event_insights)
    if not event_summary_df.empty:
        st.markdown("##### ì´ë²¤íŠ¸ë³„ ìƒì„¸ ì§€í‘œ")
        st.dataframe(
            event_summary_display,
            use_container_width=True,
            hide_index=True,
        )
    else:
        st.info("ì´ë²¤íŠ¸ë³„ ì„¸ë¶€ ì§€í‘œë¥¼ ê³„ì‚°í•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

with tab_trend:
    st.markdown("#### ê¸°ê°„ë³„ ìƒë‹´ì‹ ì²­ ìˆ˜ ì¶”ì´")
    render_chart(current_period_df)

with st.expander("ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
    st.dataframe(event_df.sort_values("ëŒ€ìƒì¼"), use_container_width=True)
